{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sympy import symbols, Eq, solve\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def load_csv(url: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(url, sep=\",\")\n",
    "\n",
    "FILENAME = \"Drug_Use_Data_from_Selected_Hospitals.csv\"\n",
    "filepath = f\"../data/{FILENAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_use_df = load_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first ~80 rows have a patient count that we can use to extrapolate counts of each condition. but it involves a bit of math, and I think we are better off doing analysis on the ratios (percentages)\n",
    "\n",
    "If we see the row \n",
    "| sex   | Start Time | End Time   | setting | all drugs |\n",
    "| ------| -----------| ---------- | ------- | ----------|\n",
    "| female| 01/01/2020 | 01/31/2020 | ip      | 23.498389 |\n",
    "| male  | 01/01/2020 | 01/31/2020 | ip      | 30.455556 |\n",
    "\n",
    "\n",
    "You can see that the percentages don't add up to 100%. This is because row reads: Given all males admitted to the hospital as In Patients for this time period, 30.4555% were admitted for condition all_drugs.\n",
    "\n",
    "In the end, I created 2 dataframes.\n",
    "- 1st with data grouped by sex categories: drug_sex_df\n",
    "- 2nd with data grouped by age categories: drug_age_df\n",
    "\n",
    "we can do EDA on each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and cleanup base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set column names to lowercase\n",
    "drug_use_df.columns = drug_use_df.columns.str.lower()\n",
    "# set row data to lowercase\n",
    "COLUMNS_TO_CONVERT_TO_LOWERCASE = ['setting', 'indicator', 'group', 'subgroup', 'measure']\n",
    "for col in COLUMNS_TO_CONVERT_TO_LOWERCASE:\n",
    "    drug_use_df[col] = drug_use_df[col].str.lower()\n",
    "\n",
    "# round values to 4 decimal places\n",
    "drug_use_df['value'] = drug_use_df['value'].round(4)\n",
    "\n",
    "# Grab the base data\n",
    "base_drug_df = drug_use_df.iloc[:82]\n",
    "\n",
    "# Remove extra columns\n",
    "COLUMNS_TO_DROP_WITH_VALUE = ['figure', 'indicator', 'group', 'subgroup', 'measure']\n",
    "base_drug_df_counts = base_drug_df.drop(columns=COLUMNS_TO_DROP_WITH_VALUE)\n",
    "\n",
    "# Remove extra columns\n",
    "COLUMNS_TO_DROP= ['figure', 'indicator', 'group', 'subgroup', 'measure', 'value']\n",
    "base_drug_df = base_drug_df.drop(columns=COLUMNS_TO_DROP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of conditions in the rows we are converting to columns\n",
    "BASE_DRUGS = ['All Drugs', 'All Opioids', 'Stimulants', 'Cannabis', 'Benzodiazepine']\n",
    "BASE_DRUGS_CO_OCCURING = ['All Drugs and co-occurring disorders', 'All Opioids and co-occurring disorders', 'Stimulants and co-occurring disorders', 'Cannabis and co-occurring disorders', 'Benzodiazepine and co-occurring disorders']\n",
    "BASE_DRUGS_COVID = ['All Drugs and COVID-19', 'All Opioids and COVID-19', 'Stimulants and COVID-19', 'Cannabis and COVID-19', 'Benzodiazepine and COVID-19']\n",
    "# Fentanyl overdose is only present for some rows, leaving out of this list\n",
    "BASE_DRUGS_OVERDOSE = ['All Opioids overdose', 'Stimulants overdose', 'Cannabis overdose', 'Benzodiazepine overdose', 'Heroin overdose']\n",
    "\n",
    "LIST_OF_NEW_DRUG_COLUMN_LISTS = [BASE_DRUGS, BASE_DRUGS_CO_OCCURING, BASE_DRUGS_COVID, BASE_DRUGS_OVERDOSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_df_with_core_columns(df: pd.DataFrame, values: list, new_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reshape a DataFrame by repeating its rows and adding a new column with specified values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame to be reshaped.\n",
    "    - values (list): A list of values to populate the new column.\n",
    "    - new_column (str): The name of the new column to be added.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The reshaped DataFrame with repeated rows and the new column.\n",
    "\n",
    "    Example:\n",
    "    Given a DataFrame:\n",
    "        date\n",
    "    0  2021\n",
    "    1  2022\n",
    "\n",
    "    Calling reshape_df_with_core_columns(df, ['male', 'female'], 'sex') will result in:\n",
    "       date     sex\n",
    "    0  2021    male\n",
    "    1  2021  female\n",
    "    2  2022    male\n",
    "    3  2022  female\n",
    "    \"\"\"\n",
    "        \n",
    "    df_repeated = df.loc[df.index.repeat(len(values))].reset_index(drop=True)\n",
    "    df_repeated[new_column] = values * len(df)\n",
    "    \n",
    "    # Reorder columns for clarity\n",
    "    columns = df_repeated.columns.tolist()\n",
    "    # Moving Setting to end\n",
    "    columns.remove('setting')\n",
    "    columns.append('setting')\n",
    "    \n",
    "    # Moving newly added column to front\n",
    "    columns.remove(new_column)\n",
    "    columns.insert(0, new_column)\n",
    "    df_repeated = df_repeated[columns]\n",
    "    \n",
    "    # Sort data and drop previous index\n",
    "    df_repeated = df_repeated.sort_values(by=['time', new_column]).reset_index(drop=True)\n",
    "    return df_repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function to lookup the corresponding values in the rows\n",
    "def transform_with_lookup_value(row, reference_df: pd.DataFrame, new_column: str, core_column: str):\n",
    "    \"\"\"\n",
    "    Look up a value in a reference DataFrame based on multiple conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    - row (pd.Series): A row from the DataFrame that needs a value lookup.\n",
    "    - reference_df (pd.DataFrame): The reference DataFrame to perform the lookup.\n",
    "    - new_column (str): The name of the column in the reference DataFrame to match against 'indicator'.\n",
    "    - core_column (str): The name of the column in the original DataFrame to match against 'subgroup' in the reference DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - value (float or int or None): The corresponding value from the 'value' column in the reference DataFrame.\n",
    "      Returns None if no match is found.\n",
    "    \n",
    "    Notes:\n",
    "    The function matches rows based on the 'time', 'subgroup', 'setting', and 'indicator' columns.\n",
    "    \"\"\"\n",
    "    matching_row = reference_df[\n",
    "        (reference_df['time'] == row['time']) & \n",
    "        (reference_df['subgroup'] == row[core_column]) &\n",
    "        (reference_df['setting'] == row['setting']) &\n",
    "        (reference_df['indicator'] == new_column)]\n",
    "    if not matching_row.empty:\n",
    "        return matching_row['value'].iloc[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_additional_columns(df: pd.DataFrame, core_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enrich the input DataFrame with additional columns based on lookup values from a global reference DataFrame.\n",
    "    \n",
    "    This function utilizes the `transform_with_lookup_value` function to populate new columns in the input DataFrame\n",
    "    based on matching criteria. The global reference DataFrame, `drug_use_df`, is filtered for rows matching the \n",
    "    specified `core_column`. For each set of new drug columns, the function looks up values and populates the input \n",
    "    DataFrame's corresponding columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame to be enriched with new columns.\n",
    "    - core_column (str): The key column name which is used to filter rows from the global reference DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The enriched DataFrame with additional columns.\n",
    "    \n",
    "    Notes:\n",
    "    - The function assumes the existence of a global DataFrame `drug_use_df`.\n",
    "    - The list `LIST_OF_NEW_DRUG_COLUMN_LISTS` is also assumed to be globally defined, containing lists of \n",
    "      column names to be added to the input DataFrame.\n",
    "    \"\"\"\n",
    "    # grab the remaining rows with our core column name\n",
    "    reference_df = drug_use_df[(drug_use_df.group == core_column)]\n",
    "    \n",
    "    for column_list in LIST_OF_NEW_DRUG_COLUMN_LISTS:\n",
    "        # lowercase all column names\n",
    "        column_list = [name.lower() for name in column_list]\n",
    "        for new_column in column_list:\n",
    "            df[new_column] = df.apply(lambda row: transform_with_lookup_value(row, reference_df, new_column, core_column), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Data by Sex\n",
    "\n",
    "organize and group the data by sex. Leaving out age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEX_VALUES = ['male', 'female']\n",
    "CORE_COLUMN_NAME = 'sex'\n",
    "\n",
    "drug_sex_df = reshape_df_with_core_columns(base_drug_df, SEX_VALUES, CORE_COLUMN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_sex_df = enrich_with_additional_columns(drug_sex_df, CORE_COLUMN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommment to save to csv\n",
    "# drug_sex_df.to_csv('../data/drug_sex.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Data by Sex with Values\n",
    "\n",
    "organize and group the data by sex. Leaving out age. Convert percentages to counts of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_equations_sex(value, total_p, m_p, f_p):\n",
    "    \"\"\"\n",
    "    Solve a system of equations to determine the counts for males (M) and females (F) based on given percentages.\n",
    "\n",
    "    The function sets up two equations based on the given values and percentages for males and females.\n",
    "    It then solves the system to determine the counts for M and F. If solutions are found, they are returned.\n",
    "    Otherwise, a message is printed indicating the missing solutions, and zeros are returned for the counts.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    value : float\n",
    "        The total value representing the sum of counts for males and females.\n",
    "    total_p : float\n",
    "        The total percentage representing the sum of percentages for drug-related counts for males and females.\n",
    "    m_p : tuple\n",
    "        A tuple containing the gender identifier for males (e.g., 'male') and its associated percentage.\n",
    "    f_p : tuple\n",
    "        A tuple containing the gender identifier for females (e.g., 'female') and its associated percentage.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple of tuples\n",
    "        The first tuple contains the gender identifier for males and its computed count.\n",
    "        The second tuple contains the gender identifier for females and its computed count.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> solve_equations(100, 50, ('male', 30), ('female', 20))\n",
    "    (('male', 60), ('female', 40))\n",
    "\n",
    "    Note:\n",
    "    -----\n",
    "    - The function assumes that the gender identifiers in m_p and f_p are 'male' and 'female', respectively.\n",
    "    - If solutions are not found for M or F, zeros are returned for their counts.\n",
    "    \"\"\"\n",
    "    M, F = symbols('M F', positive=True)\n",
    "    eq1 = Eq(M + F, value)\n",
    "    eq2 = Eq(m_p[1] * M + f_p[1] * F , total_p * value )\n",
    "    solutions = solve((eq1, eq2), (M, F))\n",
    "    if M in solutions and F in solutions:\n",
    "        # given solutions[M] is total Males admitted to the hospital\n",
    "        # Males admitted for drugs is solutions[M] * m_p[1] / 100\n",
    "        m_admitted = solutions[M] * m_p[1] / 100\n",
    "        f_admitted = solutions[F] * f_p[1] / 100\n",
    "        # we aren't guaranteed order of M vs F, so encode it in response as tuple ('male', 60)\n",
    "        return (m_p[0], m_admitted), (f_p[0], f_admitted)\n",
    "    else:\n",
    "        # Handle the case where solutions are not found for M or F\n",
    "        print(f\"Could not find solutions for {m_p[0]}:{m_p[1]} and {f_p[0]}:{f_p[1]}. With value {value} and total_percentage {total_p}\")\n",
    "        return (m_p[0], 0), (f_p[0], 0)\n",
    "    # print(solutions)\n",
    "\n",
    "def transform_with_count_sex(group, reference_df: pd.DataFrame, new_column: str, time, setting: str):\n",
    "    \"\"\"\n",
    "    Transform a group of rows to calculate drug-related counts based on reference data.\n",
    "\n",
    "    The function iterates through each row in the group and gathers equation values based \n",
    "    on the 'sex' and the new_column. Using the last row in the group and matching \n",
    "    reference data, it solves equations to compute drug-related counts for males and females. \n",
    "    The group is then updated with these computed counts.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    group : pd.DataFrame\n",
    "        The group of rows from the original dataframe that need to be transformed.\n",
    "    reference_df : pd.DataFrame\n",
    "        The dataframe containing reference data for the transformation.\n",
    "    new_column : str\n",
    "        The name of the new column in which the computed drug-related counts will be stored.\n",
    "    time : str/int\n",
    "        The time point of interest for the group.\n",
    "    setting : str\n",
    "        The setting of interest for the group.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The transformed group with updated drug-related counts.\n",
    "\n",
    "    Note:\n",
    "    -----\n",
    "    - The function relies on the `solve_equations` function to compute the drug-related counts.\n",
    "    - If no matching row is found in the reference dataframe for a given time, setting, and new_column, \n",
    "      the function will return None.\n",
    "    \"\"\"\n",
    "    equation_values = [] \n",
    "    for _, row in group.iterrows():\n",
    "        equation_values.append((row['sex'], row[new_column]))\n",
    "        \n",
    "    last_row = group.iloc[-1]\n",
    "    \n",
    "    # Match from single row\n",
    "    matching_row = reference_df[\n",
    "        (reference_df['time'] == time) & \n",
    "        (reference_df['setting'] == setting) &\n",
    "        (reference_df['indicator'] == new_column)]\n",
    "    if not matching_row.empty:\n",
    "        m_tuple, f_tuple = solve_equations_sex(last_row['value'], matching_row['value'].iloc[0], equation_values[0], equation_values[1])\n",
    "        # write count for new_column, e.g. all drugs\n",
    "        group.loc[group['sex'] == m_tuple[0], new_column] = m_tuple[1]\n",
    "        group.loc[group['sex'] == f_tuple[0], new_column] = f_tuple[1]\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_count_sex(df: pd.DataFrame, core_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enrich the input dataframe with count-based columns derived from reference data.\n",
    "\n",
    "    This function groups the dataframe by 'time' and 'setting', and then enriches it\n",
    "    with data derived from the reference data (drug_use_df) based on a matching core_column.\n",
    "    The enrichment process involves transforming the group with the `transform_with_count` function.\n",
    "    After the transformation, the resulting values are rounded to whole numbers.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The input dataframe to be enriched.\n",
    "    core_column : str\n",
    "        The column in the reference data (drug_use_df) that is used for matching.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The enriched dataframe with new count-based columns.\n",
    "\n",
    "    Note:\n",
    "    -----\n",
    "    - This function relies on the global variable `LIST_OF_NEW_DRUG_COLUMN_LISTS` for iterating through new drug columns.\n",
    "    - The function uses the global dataframe `drug_use_df` to pull the total values\n",
    "    \"\"\"\n",
    "    reference_df = drug_use_df[(drug_use_df.group == core_column)]\n",
    "    for column_list in LIST_OF_NEW_DRUG_COLUMN_LISTS:\n",
    "        # lowercase all column names\n",
    "        column_list = [name.lower() for name in column_list]\n",
    "        for new_column in column_list:\n",
    "            print(f\"converting {new_column}\")\n",
    "            df = df.groupby(['time', 'setting']).apply(\n",
    "                lambda group: transform_with_count_sex(group, reference_df, new_column, group.name[0], group.name[1]))\n",
    "            \n",
    "            # Round each count to a whole number\n",
    "            df[new_column] = df[new_column].apply(lambda x: float(x)).round(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_sex_df_for_counts = reshape_df_with_core_columns(base_drug_df_counts, SEX_VALUES, CORE_COLUMN_NAME)\n",
    "drug_sex_df_for_counts = enrich_with_additional_columns(drug_sex_df_for_counts, CORE_COLUMN_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting all drugs\n",
      "converting all opioids\n",
      "converting stimulants\n",
      "converting cannabis\n",
      "converting benzodiazepine\n",
      "converting all drugs and co-occurring disorders\n",
      "converting all opioids and co-occurring disorders\n",
      "converting stimulants and co-occurring disorders\n",
      "converting cannabis and co-occurring disorders\n",
      "converting benzodiazepine and co-occurring disorders\n",
      "converting all drugs and covid-19\n",
      "converting all opioids and covid-19\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 113888.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 35754.0 and total_percentage 0.0\n",
      "converting stimulants and covid-19\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 124275.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 113888.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 35754.0 and total_percentage 0.0\n",
      "converting cannabis and covid-19\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 35754.0 and total_percentage 0.0\n",
      "Could not find solutions for female:4.3478 and male:4.3478. With value 104826.0 and total_percentage 4.3478\n",
      "converting benzodiazepine and covid-19\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 124275.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 38478.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 113888.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 35754.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 83435.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 81635.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 34962.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 81869.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 105815.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 97345.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 54008.0 and total_percentage 0.0\n",
      "Could not find solutions for female:0.0 and male:0.0. With value 12461.0 and total_percentage 0.0\n",
      "converting all opioids overdose\n",
      "converting stimulants overdose\n",
      "converting cannabis overdose\n",
      "converting benzodiazepine overdose\n",
      "converting heroin overdose\n"
     ]
    }
   ],
   "source": [
    "drug_sex_df_count = enrich_with_count_sex(drug_sex_df_for_counts, 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>value</th>\n",
       "      <th>setting</th>\n",
       "      <th>all drugs</th>\n",
       "      <th>all opioids</th>\n",
       "      <th>stimulants</th>\n",
       "      <th>cannabis</th>\n",
       "      <th>...</th>\n",
       "      <th>all drugs and covid-19</th>\n",
       "      <th>all opioids and covid-19</th>\n",
       "      <th>stimulants and covid-19</th>\n",
       "      <th>cannabis and covid-19</th>\n",
       "      <th>benzodiazepine and covid-19</th>\n",
       "      <th>all opioids overdose</th>\n",
       "      <th>stimulants overdose</th>\n",
       "      <th>cannabis overdose</th>\n",
       "      <th>benzodiazepine overdose</th>\n",
       "      <th>heroin overdose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>01/31/2020</td>\n",
       "      <td>38478.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>4812.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2881.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>01/31/2020</td>\n",
       "      <td>124275.0</td>\n",
       "      <td>ed</td>\n",
       "      <td>18839.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17706.0</td>\n",
       "      <td>10802.0</td>\n",
       "      <td>7127.0</td>\n",
       "      <td>5122.0</td>\n",
       "      <td>3452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>01/31/2020</td>\n",
       "      <td>38478.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>5482.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3910.0</td>\n",
       "      <td>4938.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>01/31/2020</td>\n",
       "      <td>124275.0</td>\n",
       "      <td>ed</td>\n",
       "      <td>18367.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34521.0</td>\n",
       "      <td>19710.0</td>\n",
       "      <td>12138.0</td>\n",
       "      <td>9466.0</td>\n",
       "      <td>6347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>02/29/2020</td>\n",
       "      <td>35754.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>4659.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>02/29/2020</td>\n",
       "      <td>113888.0</td>\n",
       "      <td>ed</td>\n",
       "      <td>17219.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15306.0</td>\n",
       "      <td>10704.0</td>\n",
       "      <td>5352.0</td>\n",
       "      <td>5567.0</td>\n",
       "      <td>2997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>02/29/2020</td>\n",
       "      <td>35754.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>4887.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4089.0</td>\n",
       "      <td>4823.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1782.0</td>\n",
       "      <td>1678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>02/29/2020</td>\n",
       "      <td>113888.0</td>\n",
       "      <td>ed</td>\n",
       "      <td>17098.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34573.0</td>\n",
       "      <td>18410.0</td>\n",
       "      <td>10597.0</td>\n",
       "      <td>8134.0</td>\n",
       "      <td>8242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>03/01/2020</td>\n",
       "      <td>03/31/2020</td>\n",
       "      <td>32745.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2380.0</td>\n",
       "      <td>2380.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>03/01/2020</td>\n",
       "      <td>03/31/2020</td>\n",
       "      <td>97467.0</td>\n",
       "      <td>ed</td>\n",
       "      <td>14718.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>13862.0</td>\n",
       "      <td>7905.0</td>\n",
       "      <td>3682.0</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>3249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>03/01/2020</td>\n",
       "      <td>03/31/2020</td>\n",
       "      <td>32745.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>4452.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>...</td>\n",
       "      <td>642.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>3998.0</td>\n",
       "      <td>4379.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>1713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>03/01/2020</td>\n",
       "      <td>03/31/2020</td>\n",
       "      <td>97467.0</td>\n",
       "      <td>ed</td>\n",
       "      <td>15947.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30973.0</td>\n",
       "      <td>15054.0</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>6823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>04/01/2020</td>\n",
       "      <td>04/30/2020</td>\n",
       "      <td>26179.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>04/01/2020</td>\n",
       "      <td>04/30/2020</td>\n",
       "      <td>52466.0</td>\n",
       "      <td>ed</td>\n",
       "      <td>8732.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>6596.0</td>\n",
       "      <td>2502.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>2275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>04/01/2020</td>\n",
       "      <td>04/30/2020</td>\n",
       "      <td>26179.0</td>\n",
       "      <td>ip</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2065.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>2484.0</td>\n",
       "      <td>3426.0</td>\n",
       "      <td>2899.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  time  start_time    end_time     value setting  all drugs  \\\n",
       "0   female     1  01/01/2020  01/31/2020   38478.0      ip     4812.0   \n",
       "1   female     1  01/01/2020  01/31/2020  124275.0      ed    18839.0   \n",
       "2     male     1  01/01/2020  01/31/2020   38478.0      ip     5482.0   \n",
       "3     male     1  01/01/2020  01/31/2020  124275.0      ed    18367.0   \n",
       "4   female     2  02/01/2020  02/29/2020   35754.0      ip     4659.0   \n",
       "5   female     2  02/01/2020  02/29/2020  113888.0      ed    17219.0   \n",
       "6     male     2  02/01/2020  02/29/2020   35754.0      ip     4887.0   \n",
       "7     male     2  02/01/2020  02/29/2020  113888.0      ed    17098.0   \n",
       "8   female     3  03/01/2020  03/31/2020   32745.0      ip     4018.0   \n",
       "9   female     3  03/01/2020  03/31/2020   97467.0      ed    14718.0   \n",
       "10    male     3  03/01/2020  03/31/2020   32745.0      ip     4452.0   \n",
       "11    male     3  03/01/2020  03/31/2020   97467.0      ed    15947.0   \n",
       "12  female     4  04/01/2020  04/30/2020   26179.0      ip     2803.0   \n",
       "13  female     4  04/01/2020  04/30/2020   52466.0      ed     8732.0   \n",
       "14    male     4  04/01/2020  04/30/2020   26179.0      ip     3381.0   \n",
       "\n",
       "    all opioids  stimulants  cannabis  ...  all drugs and covid-19  \\\n",
       "0         583.0       230.0     303.0  ...                    15.0   \n",
       "1         767.0       580.0    1116.0  ...                     7.0   \n",
       "2         778.0       537.0     446.0  ...                    30.0   \n",
       "3        1304.0      1181.0    1641.0  ...                    37.0   \n",
       "4         630.0       236.0     280.0  ...                     7.0   \n",
       "5         774.0       593.0    1025.0  ...                     0.0   \n",
       "6         635.0       471.0     414.0  ...                    30.0   \n",
       "7        1361.0      1223.0    1563.0  ...                    17.0   \n",
       "8         535.0       230.0     271.0  ...                   375.0   \n",
       "9         678.0       556.0     747.0  ...                    89.0   \n",
       "10        702.0       457.0     352.0  ...                   642.0   \n",
       "11       1185.0      1163.0    1397.0  ...                   130.0   \n",
       "12        352.0       178.0     201.0  ...                  1219.0   \n",
       "13        481.0       403.0     437.0  ...                   486.0   \n",
       "14        472.0       348.0     308.0  ...                  2015.0   \n",
       "\n",
       "    all opioids and covid-19  stimulants and covid-19  cannabis and covid-19  \\\n",
       "0                        0.0                     50.0                    0.0   \n",
       "1                        0.0                      0.0                   45.0   \n",
       "2                       57.0                     50.0                   51.0   \n",
       "3                       60.0                      0.0                  225.0   \n",
       "4                        0.0                      0.0                    0.0   \n",
       "5                        0.0                      0.0                    0.0   \n",
       "6                        0.0                      0.0                    0.0   \n",
       "7                        0.0                      0.0                  176.0   \n",
       "8                      265.0                     48.0                   53.0   \n",
       "9                      209.0                     57.0                  182.0   \n",
       "10                     476.0                    334.0                  315.0   \n",
       "11                       0.0                      0.0                    0.0   \n",
       "12                     667.0                    348.0                  206.0   \n",
       "13                     305.0                    240.0                  301.0   \n",
       "14                    2065.0                   1941.0                  669.0   \n",
       "\n",
       "    benzodiazepine and covid-19  all opioids overdose  stimulants overdose  \\\n",
       "0                           0.0                2881.0               1646.0   \n",
       "1                           0.0               17706.0              10802.0   \n",
       "2                           0.0                3910.0               4938.0   \n",
       "3                           0.0               34521.0              19710.0   \n",
       "4                           0.0                2726.0               1468.0   \n",
       "5                           0.0               15306.0              10704.0   \n",
       "6                           0.0                4089.0               4823.0   \n",
       "7                           0.0               34573.0              18410.0   \n",
       "8                           0.0                2380.0               2380.0   \n",
       "9                         232.0               13862.0               7905.0   \n",
       "10                        577.0                3998.0               4379.0   \n",
       "11                          0.0               30973.0              15054.0   \n",
       "12                        382.0                2460.0               1669.0   \n",
       "13                        200.0                6596.0               2502.0   \n",
       "14                       2484.0                3426.0               2899.0   \n",
       "\n",
       "    cannabis overdose  benzodiazepine overdose  heroin overdose  \n",
       "0                 0.0                   1955.0           1132.0  \n",
       "1              7127.0                   5122.0           3452.0  \n",
       "2               617.0                   2572.0           1440.0  \n",
       "3             12138.0                   9466.0           6347.0  \n",
       "4               210.0                   1992.0            734.0  \n",
       "5              5352.0                   5567.0           2997.0  \n",
       "6               315.0                   1782.0           1678.0  \n",
       "7             10597.0                   8134.0           8242.0  \n",
       "8               286.0                   1809.0            666.0  \n",
       "9              3682.0                   3032.0           3249.0  \n",
       "10              476.0                   1808.0           1713.0  \n",
       "11             9313.0                   5415.0           6823.0  \n",
       "12                0.0                   1142.0            351.0  \n",
       "13             2199.0                   1516.0           2275.0  \n",
       "14              615.0                   1405.0            878.0  \n",
       "\n",
       "[15 rows x 26 columns]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_sex_df_count.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save to csv\n",
    "drug_sex_df_count.to_csv('../data/drug_sex_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Data by Age\n",
    "\n",
    "organize and group the data by age. Leaving out sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_VALUES = ['0-15 years', '16-34 years', '35-54 years', '55+ years']\n",
    "CORE_COLUMN_NAME = 'age'\n",
    "drug_age_df = reshape_df_with_core_columns(base_drug_df, AGE_VALUES, CORE_COLUMN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_age_df = enrich_with_additional_columns(drug_age_df, CORE_COLUMN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in some cases, 0-15 years data is missing for some categories. E.g. stimulants and covid. Converted to 0\n",
    "drug_age_df = drug_age_df.where(drug_age_df.notna(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_age_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_age_df.to_csv('../data/drug_age.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Data by Age with Values\n",
    "\n",
    "organize and group the data by age. Leaving out sex. Convert percentages to counts of patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
